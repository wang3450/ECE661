{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Zhang's Algorithm For Camera Calibration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Statements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from camera_callibration_helper import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.optimize import least_squares\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Images\n",
    "* raw_img_list (list): list of 40 BGR input images\n",
    "* grey_img_list (list): list of 40 grey scale input images\n",
    "* img_labels (list): list of 40 image filenames (mainly for debugging)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# given_data_path = 'C:\\\\Users\\jo_wang\\Desktop\\ECE661\\HW08\\Dataset1'\n",
    "#given_data_path = \"/Users/wang3450/Desktop/ECE661/HW08/Dataset1\"\n",
    "\n",
    "# given_data_path = \"/home/jo_wang/Desktop/ECE661/HW08/Dataset1\"\n",
    "given_data_path = \"/home/jo_wang/Desktop/ECE661/HW08/Dataset2\"\n",
    "raw_img_list, grey_img_list, img_labels = loadImages(given_data_path)\n",
    "assert(len(grey_img_list) == 4)\n",
    "assert(len(raw_img_list) == 4)\n",
    "assert(len(img_labels) == 4)\n",
    "\n",
    "# x = img_labels.index('Pic_1.jpg')\n",
    "# y = img_labels.index('Pic_5.jpg')\n",
    "# z = img_labels.index('Pic_10.jpg')\n",
    "# w = img_labels.index('Pic_34.jpg')\n",
    "#\n",
    "# print(x,y,z,w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply Canny Edge Detector On Grey Scale Images\n",
    "* edge_img_list (list): list of edge maps from Canny"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_img_list = performCanny(grey_img_list)\n",
    "assert(len(edge_img_list) == 4)\n",
    "cv2.imwrite('canny_custom1.jpg', edge_img_list[0])\n",
    "cv2.imwrite('canny_custom2.jpg', edge_img_list[1])\n",
    "cv2.imwrite('canny_custom3.jpg', edge_img_list[2])\n",
    "cv2.imwrite('canny_custom4.jpg', edge_img_list[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply Hough Transform To all the Images\n",
    "* hough_lines_list (list): list of 40 images after applying hough transform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hough_lines_list = performHoughTransform(edge_img_list)\n",
    "assert(len(hough_lines_list) == len(edge_img_list))\n",
    "\n",
    "cv2.imwrite('hough_lines_custom1.jpg', draw_hough_lines(hough_lines_list[0], deepcopy(raw_img_list[0])))\n",
    "cv2.imwrite('hough_lines_custom2.jpg', draw_hough_lines(hough_lines_list[1], deepcopy(raw_img_list[1])))\n",
    "cv2.imwrite('hough_lines_custom3.jpg', draw_hough_lines(hough_lines_list[2], deepcopy(raw_img_list[2])))\n",
    "cv2.imwrite('hough_lines_custom4.jpg', draw_hough_lines(hough_lines_list[3], deepcopy(raw_img_list[3])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the corner points from selected images\n",
    "* all_corners (list): at each index, list of 80 corner points\n",
    "* the_chosen_one (list): index of images to use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the_chosen_one = [0, 35, 1, 27]\n",
    "the_chosen_one = [0, 1, 2, 3]\n",
    "\n",
    "\n",
    "all_corners = list()\n",
    "for i in the_chosen_one:\n",
    "    h_lines, v_lines = get_Horizontal_Vert_Lines(hough_lines_list[i])\n",
    "\n",
    "    v_lines = np.array(v_lines).reshape(-1,2)\n",
    "    h_lines = np.array(h_lines).reshape(-1,2)\n",
    "\n",
    "    img = deepcopy(raw_img_list[i])\n",
    "    corner_points = getCorners(v_lines, h_lines)\n",
    "    if len(corner_points) == 80:\n",
    "        all_corners.append(corner_points)\n",
    "\n",
    "    for j, point in enumerate(corner_points):\n",
    "        try:\n",
    "            img = cv2.circle(img, point, 3, (0, 0, 255), -1)\n",
    "            cv2.putText(img, str(j), (point[0]+5, point[1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)\n",
    "        except OverflowError:\n",
    "            pass\n",
    "\n",
    "    cv2.imwrite(f'points_{i+1}.jpg', img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get world point coordinates\n",
    "* world_points (list): list of 80 world point coordinates in sorted order\n",
    "* Assumption made: squares are 20 pixels apart"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "world_points = list()\n",
    "for i in range(0, 160, 20):\n",
    "    for j in range(0, 200, 20):\n",
    "        world_points.append([i,j])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimate Homographies between world points and all corners\n",
    "* all_homographies (list): list of 3x3 homographies relating world points to each image\n",
    "* DON'T DELETE THIS ONE CUZ IT WORKS FOR NOW!!!!!!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "all_homographies = list()\n",
    "for corners in all_corners:\n",
    "    h = get_H(world_points, corners)\n",
    "    all_homographies.append(h)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute W\n",
    "* W is a 3x3 matrix\n",
    "* Derived from the solution of Vb = 0\n",
    "* Use svd to solve Vb=0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "Big_V = np.zeros((1,6))\n",
    "for h in all_homographies:\n",
    "    r1 = get_V(i=1, j=2, h=h).T\n",
    "    r2 = get_V(i=1,j=1,h=h).T - get_V(i=2,j=2,h=h).T\n",
    "    Big_V = np.vstack((Big_V, r1))\n",
    "    Big_V = np.vstack((Big_V, r2))\n",
    "\n",
    "Big_V = Big_V[1:, :]\n",
    "\n",
    "u, s, vh = np.linalg.svd(Big_V)\n",
    "b = vh[-1]\n",
    "\n",
    "w = np.zeros((3,3))\n",
    "w[0][0] = b[0]\n",
    "w[0][1] = b[1]\n",
    "w[0][2] = b[3]\n",
    "w[1][0] = b[1]\n",
    "w[1][1] = b[2]\n",
    "w[1][2] = b[4]\n",
    "w[2][0] = b[3]\n",
    "w[2][1] = b[4]\n",
    "w[2][2] = b[5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Intrinsic Camera Parameters Matrix k\n",
    "* k is 3x3 matrix\n",
    "* k is based on y0, a_x, a_y, skew, x0, lambda\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[731.2361273   -8.14104127 249.65586556]\n",
      " [  0.         734.2382484  419.03144129]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "y0 = ((w[0][1] * w[0][2]) - (w[0][0] * w[1][2])) / (w[0][0] * w[1][1] - w[0][1] ** 2)\n",
    "scale_lambda = w[2][2] - (w[0][2] ** 2 + y0 * (w[0][1] * w[0][2] - w[0][0] * w[1][2])) / w[0][0]\n",
    "a_x = np.sqrt(np.abs((scale_lambda / w[0][0])))\n",
    "a_y = np.sqrt(np.abs((scale_lambda * w[0][0]) / (w[0][0] * w[1][1] - w[0][1] **2)))\n",
    "skew = (-1 * w[0][1] * (a_x ** 2) * a_y) / scale_lambda\n",
    "x0 = (skew * y0) / a_y - (w[0][2] * (a_x ** 2)) / scale_lambda\n",
    "\n",
    "k = np.zeros((3,3))\n",
    "k[0][0] = a_x\n",
    "k[0][1] = skew\n",
    "k[0][2] = x0\n",
    "k[1][1] = a_y\n",
    "k[1][2] = y0\n",
    "k[2][2] = 1\n",
    "\n",
    "print(k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Extrinsic Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "Pic 1\n",
      "Rotation Matrix: \n",
      "[[ 0.85667399  0.07084917 -0.51096974]\n",
      " [-0.0188123   0.9941555   0.10630588]\n",
      " [ 0.51551506 -0.08145696  0.85299999]]\n",
      "Translation Matrix: \n",
      " [[-14.44781735]\n",
      " [-95.17368696]\n",
      " [253.96078731]]\n",
      "\n",
      "\n",
      "Pic 5\n",
      "Rotation Matrix: \n",
      "[[ 0.93632629  0.03682588 -0.34919469]\n",
      " [ 0.01124338  0.99083075  0.13464032]\n",
      " [ 0.35095108 -0.1299934   0.92732683]]\n",
      "Translation Matrix: \n",
      " [[-18.98573263]\n",
      " [-97.4432662 ]\n",
      " [295.54423094]]\n",
      "\n",
      "\n",
      "Pic 10\n",
      "Rotation Matrix: \n",
      "[[ 0.95250464 -0.06049478 -0.29845484]\n",
      " [ 0.02189907  0.99113949 -0.13100742]\n",
      " [ 0.30373564  0.11824929  0.94538974]]\n",
      "Translation Matrix: \n",
      " [[-27.33030725]\n",
      " [-74.6409931 ]\n",
      " [248.43488808]]\n",
      "\n",
      "\n",
      "Pic 34\n",
      "Rotation Matrix: \n",
      "[[ 0.99977776  0.01939897  0.00825283]\n",
      " [-0.02048285  0.98648914  0.16254114]\n",
      " [-0.00498819 -0.16267406  0.98666725]]\n",
      "Translation Matrix: \n",
      " [[-39.83327844]\n",
      " [-94.01846123]\n",
      " [343.75278713]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_rotations = list()\n",
    "all_translations = list()\n",
    "\n",
    "for homographies in all_homographies:\n",
    "    R, t = get_extrinsic(k, homographies)\n",
    "    all_rotations.append(R)\n",
    "    all_translations.append(t)\n",
    "\n",
    "print(len(all_rotations))\n",
    "print(len(all_translations))\n",
    "assert(len(all_rotations) == len(all_translations))\n",
    "assert(len(all_rotations) == len(the_chosen_one))\n",
    "\n",
    "print(\"Pic 1\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[0]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[0]}')\n",
    "print(\"\\n\")\n",
    "print(\"Pic 5\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[1]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[1]}')\n",
    "print(\"\\n\")\n",
    "print(\"Pic 10\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[2]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[2]}')\n",
    "print(\"\\n\")\n",
    "print(\"Pic 34\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[3]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[3]}')\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reproject the World Coordinates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic #     Mean Error             Error Variance\n",
      "Pic_1    1.9395271948198451      1.2992969118070785\n",
      "Pic_5    5.673692471060289      7.681626701637438\n",
      "Pic_10   2.144602223590031      0.8177726936095497\n",
      "Pic_34   1.1289402809715496      0.3658811309883859\n"
     ]
    }
   ],
   "source": [
    "#the_chosen_one = [0, 35, 1, 27]\n",
    "corner0 = [list(i) for i in all_corners[0]]\n",
    "corner1 = [list(i) for i in all_corners[1]]\n",
    "corner2 = [list(i) for i in all_corners[2]]\n",
    "corner3 = [list(i) for i in all_corners[3]]\n",
    "\n",
    "all_corners_list = [corner0, corner1, corner2, corner3]\n",
    "\n",
    "rep_img0, rep_img0_mean_e, rep_img0_var_e = ReprojectPoints(deepcopy(raw_img_list[0]),world_points,corner0,k,all_rotations[0],all_translations[0])\n",
    "\n",
    "rep_img1, rep_img1_mean_e, rep_img1_var_e = ReprojectPoints(deepcopy(raw_img_list[1]),world_points,corner1,k,all_rotations[1],all_translations[1])\n",
    "\n",
    "rep_img2, rep_img2_mean_e, rep_img2_var_e = ReprojectPoints(deepcopy(raw_img_list[2]),world_points,corner2,k,all_rotations[2],all_translations[2])\n",
    "\n",
    "rep_img3, rep_img3_mean_e, rep_img3_var_e = ReprojectPoints(deepcopy(raw_img_list[3]),world_points,corner3,k,all_rotations[3],all_translations[3])\n",
    "\n",
    "cv2.imwrite('rep_custom1.jpg', rep_img0)\n",
    "cv2.imwrite('rep_custom2.jpg', rep_img1)\n",
    "cv2.imwrite('rep_custom3.jpg', rep_img2)\n",
    "cv2.imwrite('rep_custom4.jpg', rep_img3)\n",
    "\n",
    "print('Pic #     Mean Error             Error Variance')\n",
    "print(f'Pic_1    {rep_img0_mean_e}      {rep_img0_var_e}')\n",
    "print(f'Pic_5    {rep_img1_mean_e}      {rep_img1_var_e}')\n",
    "print(f'Pic_10   {rep_img2_mean_e}      {rep_img2_var_e}')\n",
    "print(f'Pic_34   {rep_img3_mean_e}      {rep_img3_var_e}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Refinement of Calibration Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1). Prepare p0 depending on whether we want to consider radial distortion\n",
    "2). Express R as rodriguez form\n",
    "3). Resize translations (3,1) -> (3,)\n",
    "\n",
    "p0 is constituted by the intrinsic and extrinsic parameters\n",
    "* pack k = [a_x, a_y, s, x0, y0] into first 5 index of p\n",
    "* pack the linear least squares estimated rotational and translational matrices for each view thereafter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "rodrigues_rotation = list()\n",
    "for R in all_rotations:\n",
    "    rodrigues_rotation.append(rotation2rod(R))\n",
    "\n",
    "translations_for_refine = [np.resize(translation, (3,)) for translation in all_translations]\n",
    "\n",
    "'''Create p0 to be optimized (no radial distortion)'''\n",
    "rad_dist = False\n",
    "if rad_dist:\n",
    "    k1,k2 = np.zeros(2)\n",
    "    p0=np.zeros(7+6*len(the_chosen_one))\n",
    "    p0[:5]=np.array([a_x,a_y,skew,x0,y0])\n",
    "    for i in range(len(the_chosen_one)):\n",
    "        p0[6*i+5:6*i+8]=rodrigues_rotation[i]\n",
    "        p0[6*i+8:6*i+11]=translations_for_refine[i]\n",
    "    p0[-2]=k1;  p0[-1]=k2\n",
    "else:\n",
    "    p0=np.zeros(5+6*len(the_chosen_one))\n",
    "    p0[:5]=np.array([a_x,a_y,skew,x0,y0])\n",
    "    for i in range(len(the_chosen_one)):\n",
    "        p0[6*i+5:6*i+8]=rodrigues_rotation[i]\n",
    "        p0[6*i+8:6*i+11]=translations_for_refine[i]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Call the optimizer with:\n",
    "    * cost_function\n",
    "    * parameter to be optimized (p0)\n",
    "    * method = \"lm\"\n",
    "    * args = (all_corners_list, world_point)\n",
    "\n",
    "Note: all_corners_list = [corners0, corners1, corners,2]\n",
    "where [cornersX] = [[x1,y1], [x2,y2], ..., [xn,yn]]\n",
    "\n",
    "Optimum p_star = optim['x']\n",
    "p_star is same shape as p0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "if rad_dist:\n",
    "    optim=least_squares(cost_function_yes_rad,p0,method='lm',args=(all_corners_list,world_points))\n",
    "else:\n",
    "    optim=least_squares(cost_function_no_rad,p0, method='lm',args=(all_corners_list,world_points))\n",
    "\n",
    "p_star=optim['x']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unpack the intrinsic and extrinsic parameters from p_star\n",
    "* k = [a_x, a_y, s, x0, y0] located in first 5 indexes of p_star\n",
    "* unpack the refined rotational and translational matrices for each view."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "a_x=p_star[0]\n",
    "a_y=p_star[1]\n",
    "skew=p_star[2]\n",
    "x0=p_star[3]\n",
    "y0=p_star[4]\n",
    "\n",
    "K_ref = np.zeros((3,3))\n",
    "K_ref[0][0] = a_x\n",
    "K_ref[0][1] = skew\n",
    "K_ref[0][2] = x0\n",
    "K_ref[1][1] = a_y\n",
    "K_ref[1][2] = y0\n",
    "K_ref[2][2] = 1\n",
    "\n",
    "if rad_dist:\n",
    "    k1=p_star[-2]; k2=p_star[-1]\n",
    "    print('Radial Distortion parameters: k1='+str(k1)+' k2='+str(k2))\n",
    "\n",
    "R_ref=[]\n",
    "t_ref=[]\n",
    "for i in range(len(the_chosen_one)):\n",
    "    iw=p_star[6*i+5:6*i+8]\n",
    "    it=p_star[6*i+8:6*i+11]\n",
    "    iR=rod2rotation(iw)\n",
    "    R_ref.append(iR)\n",
    "    t_ref.append(it)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic #     Mean Error             Error Variance\n",
      "Pic_1    1.0546385262583342      0.3670784602174079\n",
      "Pic_5    1.1115186663304994      0.2962818868566509\n",
      "Pic_10   1.0638838434119937      0.31979058085783557\n",
      "Pic_34   0.6750958706654441      0.14351495132804515\n"
     ]
    }
   ],
   "source": [
    "t_ref[0] = np.reshape(t_ref[0], (3,1))\n",
    "t_ref[1] = np.reshape(t_ref[1], (3,1))\n",
    "t_ref[2] = np.reshape(t_ref[2], (3,1))\n",
    "t_ref[3] = np.reshape(t_ref[3], (3,1))\n",
    "refine_img0, refine_img0_mean_e, refine_img0_var_e = ReprojectPoints(raw_img_list[0],world_points,corner0,K_ref,R_ref[0],t_ref[0])\n",
    "refine_img1, refine_img1_mean_e, refine_img1_var_e = ReprojectPoints(raw_img_list[1],world_points,corner1,K_ref,R_ref[1],t_ref[1])\n",
    "refine_img2, refine_img2_mean_e, refine_img2_var_e = ReprojectPoints(raw_img_list[2],world_points,corner2,K_ref,R_ref[2],t_ref[2])\n",
    "refine_img3, refine_img3_mean_e, refine_img3_var_e = ReprojectPoints(raw_img_list[3],world_points,corner3,K_ref,R_ref[3],t_ref[3])\n",
    "\n",
    "cv2.imwrite('refine_no_rad_pic1.jpg', refine_img0)\n",
    "cv2.imwrite('refine_no_rad_pic5.jpg', refine_img1)\n",
    "cv2.imwrite('refine_no_rad_pic10.jpg', refine_img2)\n",
    "cv2.imwrite('refine_no_rad_pic34.jpg', refine_img3)\n",
    "\n",
    "print('Pic #     Mean Error             Error Variance')\n",
    "print(f'Pic_1    {refine_img0_mean_e}      {refine_img0_var_e}')\n",
    "print(f'Pic_5    {refine_img1_mean_e}      {refine_img1_var_e}')\n",
    "print(f'Pic_10   {refine_img2_mean_e}      {refine_img2_var_e}')\n",
    "print(f'Pic_34   {refine_img3_mean_e}      {refine_img3_var_e}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
