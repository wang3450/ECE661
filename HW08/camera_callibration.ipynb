{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Zhang's Algorithm For Camera Calibration"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Statements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from camera_callibration_helper import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from scipy.optimize import least_squares\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Images\n",
    "* raw_img_list (list): list of 40 BGR input images\n",
    "* grey_img_list (list): list of 40 grey scale input images\n",
    "* img_labels (list): list of 40 image filenames (mainly for debugging)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 35 1 27\n"
     ]
    }
   ],
   "source": [
    "# given_data_path = 'C:\\\\Users\\jo_wang\\Desktop\\ECE661\\HW08\\Dataset1'\n",
    "given_data_path = \"/Users/wang3450/Desktop/ECE661/HW08/Dataset1\"\n",
    "raw_img_list, grey_img_list, img_labels = loadImages(given_data_path)\n",
    "assert(len(grey_img_list) == 40)\n",
    "assert(len(raw_img_list) == 40)\n",
    "assert(len(img_labels) == 40)\n",
    "\n",
    "x = img_labels.index('Pic_1.jpg')\n",
    "y = img_labels.index('Pic_5.jpg')\n",
    "z = img_labels.index('Pic_10.jpg')\n",
    "w = img_labels.index('Pic_34.jpg')\n",
    "\n",
    "print(x,y,z,w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply Canny Edge Detector On Grey Scale Images\n",
    "* edge_img_list (list): list of edge maps from Canny"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_img_list = performCanny(grey_img_list)\n",
    "assert(len(edge_img_list) == 40)\n",
    "cv2.imwrite('canny_pic1.jpg', edge_img_list[0])\n",
    "cv2.imwrite('canny_pic5.jpg', edge_img_list[35])\n",
    "cv2.imwrite('canny_pic10.jpg', edge_img_list[1])\n",
    "cv2.imwrite('canny_pic34.jpg', edge_img_list[27])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply Hough Transform To all the Images\n",
    "* hough_lines_list (list): list of 40 images after applying hough transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hough_lines_list = performHoughTransform(edge_img_list)\n",
    "assert(len(hough_lines_list) == len(edge_img_list))\n",
    "\n",
    "cv2.imwrite('hough_lines_pic1.jpg', draw_hough_lines(hough_lines_list[0], deepcopy(raw_img_list[0])))\n",
    "cv2.imwrite('hough_lines_pic5.jpg', draw_hough_lines(hough_lines_list[35], deepcopy(raw_img_list[35])))\n",
    "cv2.imwrite('hough_lines_pic10.jpg', draw_hough_lines(hough_lines_list[1], deepcopy(raw_img_list[1])))\n",
    "cv2.imwrite('hough_lines_pic34.jpg', draw_hough_lines(hough_lines_list[27], deepcopy(raw_img_list[27])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the corner points from selected images\n",
    "* all_corners (list): at each index, list of 80 corner points\n",
    "* the_chosen_one (list): index of images to use"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "the_chosen_one = [0, 35, 1, 27]\n",
    "\n",
    "\n",
    "all_corners = list()\n",
    "for i in the_chosen_one:\n",
    "    h_lines, v_lines = get_Horizontal_Vert_Lines(hough_lines_list[i])\n",
    "\n",
    "    v_lines = np.array(v_lines).reshape(-1,2)\n",
    "    h_lines = np.array(h_lines).reshape(-1,2)\n",
    "\n",
    "    img = deepcopy(raw_img_list[i])\n",
    "    corner_points = getCorners(v_lines, h_lines)\n",
    "    if len(corner_points) == 80:\n",
    "        all_corners.append(corner_points)\n",
    "\n",
    "    for j, point in enumerate(corner_points):\n",
    "        try:\n",
    "            img = cv2.circle(img, point, 3, (0, 0, 255), -1)\n",
    "            cv2.putText(img, str(j), (point[0]+5, point[1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)\n",
    "        except OverflowError:\n",
    "            pass\n",
    "\n",
    "    cv2.imwrite(f'points_{i}.jpg', img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get world point coordinates\n",
    "* world_points (list): list of 80 world point coordinates in sorted order\n",
    "* Assumption made: squares are 20 pixels apart"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "world_points = list()\n",
    "for i in range(0, 160, 20):\n",
    "    for j in range(0, 200, 20):\n",
    "        world_points.append([i,j])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimate Homographies between world points and all corners\n",
    "* all_homographies (list): list of 3x3 homographies relating world points to each image\n",
    "* DON'T DELETE THIS ONE CUZ IT WORKS FOR NOW!!!!!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "all_homographies = list()\n",
    "for corners in all_corners:\n",
    "    h = get_H(world_points, corners)\n",
    "    all_homographies.append(h)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute W\n",
    "* W is a 3x3 matrix\n",
    "* Derived from the solution of Vb = 0\n",
    "* Use svd to solve Vb=0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "Big_V = np.zeros((1,6))\n",
    "for h in all_homographies:\n",
    "    r1 = get_V(i=1, j=2, h=h).T\n",
    "    r2 = get_V(i=1,j=1,h=h).T - get_V(i=2,j=2,h=h).T\n",
    "    Big_V = np.vstack((Big_V, r1))\n",
    "    Big_V = np.vstack((Big_V, r2))\n",
    "\n",
    "Big_V = Big_V[1:, :]\n",
    "\n",
    "u, s, vh = np.linalg.svd(Big_V)\n",
    "b = vh[-1]\n",
    "\n",
    "w = np.zeros((3,3))\n",
    "w[0][0] = b[0]\n",
    "w[0][1] = b[1]\n",
    "w[0][2] = b[3]\n",
    "w[1][0] = b[1]\n",
    "w[1][1] = b[2]\n",
    "w[1][2] = b[4]\n",
    "w[2][0] = b[3]\n",
    "w[2][1] = b[4]\n",
    "w[2][2] = b[5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Intrinsic Camera Parameters Matrix k\n",
    "* k is 3x3 matrix\n",
    "* k is based on y0, a_x, a_y, skew, x0, lambda\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.27611186e+02 2.60919073e-02 3.20441973e+02]\n",
      " [0.00000000e+00 7.26434435e+02 2.42237902e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "y0 = ((w[0][1] * w[0][2]) - (w[0][0] * w[1][2])) / (w[0][0] * w[1][1] - w[0][1] ** 2)\n",
    "scale_lambda = w[2][2] - (w[0][2] ** 2 + y0 * (w[0][1] * w[0][2] - w[0][0] * w[1][2])) / w[0][0]\n",
    "a_x = np.sqrt(np.abs((scale_lambda / w[0][0])))\n",
    "a_y = np.sqrt(np.abs((scale_lambda * w[0][0]) / (w[0][0] * w[1][1] - w[0][1] **2)))\n",
    "skew = (-1 * w[0][1] * (a_x ** 2) * a_y) / scale_lambda\n",
    "x0 = (skew * y0) / a_y - (w[0][2] * (a_x ** 2)) / scale_lambda\n",
    "\n",
    "k = np.zeros((3,3))\n",
    "k[0][0] = a_x\n",
    "k[0][1] = skew\n",
    "k[0][2] = x0\n",
    "k[1][1] = a_y\n",
    "k[1][2] = y0\n",
    "k[2][2] = 1\n",
    "\n",
    "print(k)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Compute Extrinsic Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic 1\n",
      "Rotation Matrix: \n",
      "[[ 0.78755375 -0.18504673  0.58780677]\n",
      " [ 0.19763533  0.97930997  0.04350012]\n",
      " [-0.58369458  0.0819127   0.80783101]]\n",
      "Translation Matrix: \n",
      " [[ -37.29988982]\n",
      " [-103.08370954]\n",
      " [ 441.81089493]]\n",
      "\n",
      "\n",
      "Pic 5\n",
      "Rotation Matrix: \n",
      "[[ 0.98777016 -0.15501223  0.01677272]\n",
      " [ 0.15578832  0.98559751 -0.06578405]\n",
      " [-0.00633382  0.06759252  0.99769291]]\n",
      "Translation Matrix: \n",
      " [[-43.01419107]\n",
      " [-98.01655764]\n",
      " [420.27097024]]\n",
      "\n",
      "\n",
      "Pic 10\n",
      "Rotation Matrix: \n",
      "[[ 0.74717874  0.1886999  -0.63727253]\n",
      " [ 0.13193634  0.89765281  0.42049046]\n",
      " [ 0.65139599 -0.39826094  0.64581073]]\n",
      "Translation Matrix: \n",
      " [[-58.55024996]\n",
      " [-95.95843495]\n",
      " [426.46924173]]\n",
      "\n",
      "\n",
      "Pic 34\n",
      "Rotation Matrix: \n",
      "[[ 0.93722295 -0.12121838 -0.32698508]\n",
      " [ 0.08510211  0.98879608 -0.12263744]\n",
      " [ 0.33818748  0.08711151  0.93703832]]\n",
      "Translation Matrix: \n",
      " [[-59.12062571]\n",
      " [-99.19596354]\n",
      " [314.35583947]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_rotations = list()\n",
    "all_translations = list()\n",
    "\n",
    "for homographies in all_homographies:\n",
    "    R, t = get_extrinsic(k, homographies)\n",
    "    all_rotations.append(R)\n",
    "    all_translations.append(t)\n",
    "\n",
    "assert(len(all_rotations) == len(all_translations))\n",
    "assert(len(all_rotations) == len(the_chosen_one))\n",
    "\n",
    "print(\"Pic 1\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[0]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[0]}')\n",
    "print(\"\\n\")\n",
    "print(\"Pic 5\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[1]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[1]}')\n",
    "print(\"\\n\")\n",
    "print(\"Pic 10\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[2]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[2]}')\n",
    "print(\"\\n\")\n",
    "print(\"Pic 34\")\n",
    "print(f'Rotation Matrix: \\n{all_rotations[3]}')\n",
    "print(f'Translation Matrix: \\n {all_translations[3]}')\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reproject the World Coordinates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic #     Mean Error             Error Variance\n",
      "Pic_1    1.2124966087180533      0.4419708546416626\n",
      "Pic_5    0.6834195902286995      0.11333566797308778\n",
      "Pic_10   0.8883294030357984      0.2100304351027858\n",
      "Pic_34   1.0073327588105954      0.2513307337281006\n"
     ]
    }
   ],
   "source": [
    "#the_chosen_one = [0, 35, 1, 27]\n",
    "corner0 = [list(i) for i in all_corners[0]]\n",
    "corner1 = [list(i) for i in all_corners[1]]\n",
    "corner2 = [list(i) for i in all_corners[2]]\n",
    "corner3 = [list(i) for i in all_corners[3]]\n",
    "\n",
    "all_corners_list = [corner0, corner1, corner2, corner3]\n",
    "\n",
    "rep_img0, rep_img0_mean_e, rep_img0_var_e = ReprojectPoints(raw_img_list[0],world_points,corner0,k,all_rotations[0],all_translations[0])\n",
    "\n",
    "rep_img1, rep_img1_mean_e, rep_img1_var_e = ReprojectPoints(raw_img_list[35],world_points,corner1,k,all_rotations[1],all_translations[1])\n",
    "\n",
    "rep_img2, rep_img2_mean_e, rep_img2_var_e = ReprojectPoints(raw_img_list[1],world_points,corner2,k,all_rotations[2],all_translations[2])\n",
    "\n",
    "rep_img3, rep_img3_mean_e, rep_img3_var_e = ReprojectPoints(raw_img_list[27],world_points,corner3,k,all_rotations[3],all_translations[3])\n",
    "\n",
    "cv2.imwrite('rep_pic1.jpg', rep_img0)\n",
    "cv2.imwrite('rep_pic5.jpg', rep_img1)\n",
    "cv2.imwrite('rep_pic10.jpg', rep_img2)\n",
    "cv2.imwrite('rep_pic34.jpg', rep_img3)\n",
    "\n",
    "print('Pic #     Mean Error             Error Variance')\n",
    "print(f'Pic_1    {rep_img0_mean_e}      {rep_img0_var_e}')\n",
    "print(f'Pic_5    {rep_img1_mean_e}      {rep_img1_var_e}')\n",
    "print(f'Pic_10   {rep_img2_mean_e}      {rep_img2_var_e}')\n",
    "print(f'Pic_34   {rep_img3_mean_e}      {rep_img3_var_e}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Refinement of Calibration Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1). Prepare p0 depending on whether we want to consider radial distortion\n",
    "2). Express R as rodriguez form\n",
    "3). Resize translations (3,1) -> (3,)\n",
    "\n",
    "p0 is constituted by the intrinsic and extrinsic parameters\n",
    "* pack k = [a_x, a_y, s, x0, y0] into first 5 index of p\n",
    "* pack the linear least squares estimated rotational and translational matrices for each view thereafter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "rodrigues_rotation = list()\n",
    "for R in all_rotations:\n",
    "    rodrigues_rotation.append(rotation2rod(R))\n",
    "\n",
    "translations_for_refine = [np.resize(translation, (3,)) for translation in all_translations]\n",
    "\n",
    "'''Create p0 to be optimized (no radial distortion)'''\n",
    "rad_dist = True\n",
    "if rad_dist:\n",
    "    k1,k2 = np.zeros(2)\n",
    "    p0=np.zeros(7+6*len(the_chosen_one))\n",
    "    p0[:5]=np.array([a_x,a_y,skew,x0,y0])\n",
    "    for i in range(len(the_chosen_one)):\n",
    "        p0[6*i+5:6*i+8]=rodrigues_rotation[i]\n",
    "        p0[6*i+8:6*i+11]=translations_for_refine[i]\n",
    "    p0[-2]=k1;  p0[-1]=k2\n",
    "else:\n",
    "    p0=np.zeros(5+6*len(the_chosen_one))\n",
    "    p0[:5]=np.array([a_x,a_y,skew,x0,y0])\n",
    "    for i in range(len(the_chosen_one)):\n",
    "        p0[6*i+5:6*i+8]=rodrigues_rotation[i]\n",
    "        p0[6*i+8:6*i+11]=translations_for_refine[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Call the optimizer with:\n",
    "    * cost_function\n",
    "    * parameter to be optimized (p0)\n",
    "    * method = \"lm\"\n",
    "    * args = (all_corners_list, world_point)\n",
    "\n",
    "Note: all_corners_list = [corners0, corners1, corners,2]\n",
    "where [cornersX] = [[x1,y1], [x2,y2], ..., [xn,yn]]\n",
    "\n",
    "Optimum p_star = optim['x']\n",
    "p_star is same shape as p0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "if rad_dist:\n",
    "    optim=least_squares(cost_function_yes_rad,p0,method='lm',args=(all_corners_list,world_points))\n",
    "else:\n",
    "    optim=least_squares(cost_function_no_rad,p0, method='lm',args=(all_corners_list,world_points))\n",
    "\n",
    "p_star=optim['x']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Unpack the intrinsic and extrinsic parameters from p_star\n",
    "* k = [a_x, a_y, s, x0, y0] located in first 5 indexes of p_star\n",
    "* unpack the refined rotational and translational matrices for each view."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radial Distortion parameters: k1=-1.7930708530386655e-07 k2=7.915913690154872e-13\n"
     ]
    }
   ],
   "source": [
    "a_x=p_star[0]\n",
    "a_y=p_star[1]\n",
    "skew=p_star[2]\n",
    "x0=p_star[3]\n",
    "y0=p_star[4]\n",
    "\n",
    "K_ref = np.zeros((3,3))\n",
    "K_ref[0][0] = a_x\n",
    "K_ref[0][1] = skew\n",
    "K_ref[0][2] = x0\n",
    "K_ref[1][1] = a_y\n",
    "K_ref[1][2] = y0\n",
    "K_ref[2][2] = 1\n",
    "\n",
    "if rad_dist:\n",
    "    k1=p_star[-2]; k2=p_star[-1]\n",
    "    print('Radial Distortion parameters: k1='+str(k1)+' k2='+str(k2))\n",
    "\n",
    "R_ref=[]\n",
    "t_ref=[]\n",
    "for i in range(len(the_chosen_one)):\n",
    "    iw=p_star[6*i+5:6*i+8]\n",
    "    it=p_star[6*i+8:6*i+11]\n",
    "    iR=rod2rotation(iw)\n",
    "    R_ref.append(iR)\n",
    "    t_ref.append(it)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pic #     Mean Error             Error Variance\n",
      "Pic_1    0.9566193624472742      0.277279372102838\n",
      "Pic_5    0.6971250547731309      0.14996576881318496\n",
      "Pic_10   0.7865193333734151      0.1926577380734602\n",
      "Pic_34   1.1251765174624146      0.44512019135767317\n"
     ]
    }
   ],
   "source": [
    "t_ref[0] = np.reshape(t_ref[0], (3,1))\n",
    "t_ref[1] = np.reshape(t_ref[1], (3,1))\n",
    "t_ref[2] = np.reshape(t_ref[2], (3,1))\n",
    "t_ref[3] = np.reshape(t_ref[3], (3,1))\n",
    "refine_img0, refine_img0_mean_e, refine_img0_var_e = ReprojectPoints(raw_img_list[0],world_points,corner0,K_ref,R_ref[0],t_ref[0])\n",
    "refine_img1, refine_img1_mean_e, refine_img1_var_e = ReprojectPoints(raw_img_list[35],world_points,corner1,K_ref,R_ref[1],t_ref[1])\n",
    "refine_img2, refine_img2_mean_e, refine_img2_var_e = ReprojectPoints(raw_img_list[1],world_points,corner2,K_ref,R_ref[2],t_ref[2])\n",
    "refine_img3, refine_img3_mean_e, refine_img3_var_e = ReprojectPoints(raw_img_list[27],world_points,corner3,K_ref,R_ref[3],t_ref[3])\n",
    "\n",
    "cv2.imwrite('refine_yes_rad_pic1.jpg', refine_img0)\n",
    "cv2.imwrite('refine_yes_rad_pic5.jpg', refine_img1)\n",
    "cv2.imwrite('refine_yes_rad_pic10.jpg', refine_img2)\n",
    "cv2.imwrite('refine_yes_rad_pic34.jpg', refine_img3)\n",
    "\n",
    "print('Pic #     Mean Error             Error Variance')\n",
    "print(f'Pic_1    {refine_img0_mean_e}      {refine_img0_var_e}')\n",
    "print(f'Pic_5    {refine_img1_mean_e}      {refine_img1_var_e}')\n",
    "print(f'Pic_10   {refine_img2_mean_e}      {refine_img2_var_e}')\n",
    "print(f'Pic_34   {refine_img3_mean_e}      {refine_img3_var_e}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}